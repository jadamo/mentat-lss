
model:  MLP_single_tracer

num_cosmo_params : 4
cosmo_params : 
  h       : [0.4, 1.0]
  omega_c : [0.05, 0.3]
  As      : [1.2e-9,2.7e-9]
  fnl     : [-50, 50]
num_bias_params : 1 # The number of nuisance parameters per tracer
bias_params : 
  b1 : [1., 4.]

output_kbins : 25

num_tracers : 1
num_zbins   : 1
z_eff: [0.5]

num_mlp_blocks      : 1
mlp_dims            : [10, 40]
num_block_layers    : 3
use_batchnorm       : True
use_skip_connection : True

# Training parameters
num_epochs: 300
learning_rate: [1.0e-3]
batch_size: 25
early_stopping_epochs: 25
weight_initialization: He
optimizer : Adam
use_gpu : True

# Where to save the network
save_dir: /home/joeadamo/Research/SPHEREx/spherex_emu/emulators/mlp_single_tracer/
# Where your training set lives
training_dir: /home/joeadamo/Research/Data/SPHEREx-Data/Training-Set-EFT/